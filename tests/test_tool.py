

from typing import Optional, Literal, TypedDict, Annotated, cast
from langgraph.types import Command
from langgraph.graph import add_messages
from langchain_core.messages import ToolCall, HumanMessage,AIMessage, ToolMessage, AnyMessage,SystemMessage
from my_codeact.utils.prompt_builder import build_system_prompt
from langchain.chat_models import init_chat_model


from langgraph.prebuilt import ToolNode
# get all tools
# tool defined by "@tool"
from my_codeact.tools.jupyter_tool import JUPYTER_TOOLS
tools = JUPYTER_TOOLS
tool_node = ToolNode(tools)

class AgentState(TypedDict):
    messages: Annotated[list[AnyMessage], add_messages]
    current_tool_calls: Optional[ToolCall]
    last_observation: Optional[str] 
#    reflection: Optional[str]

    #code: Optional[str]
    #exec_result: Optional[str]


def call_model(state: AgentState) -> Command[Literal["tool_executor", "__end__"]]:
    
    messages = state["messages"]

    llm = init_chat_model("ollama:mistral:7b")

    response: AIMessage = cast(AIMessage,llm.invoke(messages))
    tool_calls: Optional[list[ToolCall]] = response.tool_calls

    if tool_calls:
        # goto tool node

        return Command(
            update={
                "messages": response,
                "current_tool_calls": tool_calls
            },
            goto="tool_executor"
        )
    else:
        # to end
        return Command(
            update={
                "messages": response,
            },
            goto="__end__"
        )
    
def tool_executor(state: AgentState) :
    messages = state["messages"]
    # latest msgs are tool call
    tool_calls = state["current_tool_calls"]
    observation = [] # also could be reflection
    if not tool_calls:
        return Command(
            goto="call_model"
        )
    # execute the tools
    for tool_call in tool_calls:
        result: ToolMessage = tool_node.invoke(tool_call)
        observation.append(result)


    return Command(
        update={
            "messages": observation,
            "current_tool_calls": None,
            "last_observation": observation[-1].content if observation else None
            },
            goto="call_model"
        )


from langgraph.graph import StateGraph

agent = StateGraph(AgentState)
agent.add_node("call_model",call_model)
agent.add_node("tool_executor", tool_executor)

agent.set_entry_point("call_model")



# --------------
# ä½¿ç”¨ç¤ºä¾‹
initial_state: AgentState = {
    "messages": [HumanMessage(content=""""
#è§’è‰²ï¼š
ä½ æ˜¯ä¸€ä¸ªæ™ºèƒ½åŠ©æ‰‹ã€‚ä½ éœ€è¦é€šè¿‡ç¼–å†™å’Œæ‰§è¡ŒPythonä»£ç æ¥å®Œæˆä»»åŠ¡ã€‚

æ‰§è¡Œè§„åˆ™:
1. ä½¿ç”¨Pythonä»£ç å—(```python)æ¥æ‰§è¡Œæ“ä½œ
2. ç³»ç»Ÿä¼šæ˜¾ç¤ºå®Œæ•´çš„æ‰§è¡Œè¿‡ç¨‹ï¼ŒåŒ…æ‹¬ä»£ç ã€è¾“å‡ºã€è¿”å›å€¼ç­‰
3. å¯ä»¥å¼•ç”¨ä¹‹å‰ä»£ç ç‰‡æ®µä¸­å®šä¹‰çš„å˜é‡
4. å¦‚æœä¸éœ€è¦æ‰§è¡Œä»£ç ï¼Œç›´æ¥ç”¨æ–‡æœ¬å›å¤ç”¨æˆ·
5. å»ºè®®åœ¨ä»£ç ä¸­ä½¿ç”¨print()æ¥è¾“å‡ºä¸­é—´ç»“æœï¼Œä¾¿äºè°ƒè¯•

è¾“å‡ºè¯´æ˜:
- ğŸ“ æ˜¾ç¤ºå®é™…æ‰§è¡Œçš„ä»£ç 
- ğŸ“¤ æ˜¾ç¤ºprint()ç­‰æ ‡å‡†è¾“å‡º  
- ğŸ’¡ æ˜¾ç¤ºè¡¨è¾¾å¼çš„è¿”å›å€¼
- ğŸ¨ æ˜¾ç¤ºmatplotlibå›¾è¡¨ç­‰å¯è§†åŒ–å†…å®¹
- âš ï¸ æ˜¾ç¤ºè­¦å‘Šä¿¡æ¯
- âœ… è¡¨ç¤ºä»£ç æ‰§è¡Œå®Œæˆ

    è¯·å¸®æˆ‘è®¡ç®— 1åˆ°9019çš„å’Œ""")],
    "current_tool_calls": None,
    "last_observation": None
}



#print(agent.compile().invoke(initial_state))
def create_agent():
   return  agent.compile()



for step in agent.compile().stream(initial_state):
   print(step)


    
